# 03. 并发理论(JMM)

## JMM
JMM 全称：Java Memory Model。是一种虚拟机规范，用于屏蔽掉各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的并发效果。主要规定了以下两点
>1. 规定了一个线程如何以及何时可以看到其他线程修改过后的共享变量的值，即线程之间共享变量的可见性
>2. 如何在需要的时候对共享变量进行同步

而在并发编程中，我们所要处理的两个关键问题就是这两条标准的体现：线程之间如何通信以及线程之间如何同步。通信是指线程之间以何种机制来交换信息。在命令式的编程中，线程之间的通信机制有两种：共享内存和消息传递。

在共享内存并发的模型里，线程之间共享程序的公共状态，线程之间通过读-写内存中的公共状态来隐式进行通信。

在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显示进行通信，在java中典型的消息传递方式就是 wait() 和 notify()。

Java 的并发采用的就是 **共享内存模型**，Java 线程之间的通信总是隐式进行的，整个通信过程对程序员是完全透明的。这里提到的共享内存模型指的就是 Java 内存模型(简称 JMM )


## JMM 抽象结构模型  
JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。
![Alt 'JMM 内存结构抽象结构示意图'](https://s2.ax1x.com/2019/12/29/lK1Ev9.png)

从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤：
>1. 线程A把本地内存A中更新过的共享变量刷新到主内存中去
>2. 线程B到主内存中去读取线程A之前已更新过的共享变量

## JVM 对 Java 内存模型的实现

![Alt 'JVM 区域图'](https://s2.ax1x.com/2019/12/30/lM9cdI.png)


JVM 在执行 Java 程序的过程中会把它所管理的内存划分为若干不同的数据区域，这些区域都有各自的用途以及创建和销毁的时间。

主要包含 2 类：
>1. 线程共享区域：方法区（Method Area）和 堆（Heap）
>2. 线程私有区域：虚拟机栈（VM Stack），本地方法栈（Native Method Stack），程序计数器（PC Register）

**具体的区分如下：**

![Alt 'JVM 区域划分'](https://s2.ax1x.com/2019/12/30/lM9RFP.jpg)

**虚拟机栈** 每一个运行在Java虚拟机上的线程都拥有自己的线程栈。每个方法在执行的时候都会创建一个栈帧用于存储局部变量表、操作数栈、动态链表、方法出口信息等。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。栈的生命周期与线程相同。

**本地方法栈** 本地方法栈与虚拟机栈的作用相似，不同之处在于虚拟机栈为虚拟机执行的Java方法服务，而本地方法栈则为虚拟机使用到的Native方法服务

**程序计数器** 程序计数器保存着每一条线程下一次执行指令位置

**堆** 用来保存程序中所创建的所有对象、数组元素

**方法区** 方法区是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据

### 数据存储总结
>1. 一个本地变量是原始类型, 它会被完全存储到栈区
>2. 一个本地变量是引用类型, 这个本地引用会被存储到栈中，但是对象本身仍然存储在堆区
>3. 一个对象的成员方法，方法中包含局部变量，存储在栈区
>4. 一个对象的成员变量，不管它是原始类型还是包装类型，都存储到堆区
>5. Static 类型的变量以及类本身相关信息都会随着类本身存储在堆区


## JMM 带来的问题

### 可见性问题
![Alt '可见性问题'](https://s2.ax1x.com/2019/12/30/lQPuQO.png)
如上图，3个count，2个为副本。启动2个线程对count进行累加，线程1更改count的时候，如果不刷新到主内存，线程2还在对原来的值进行累加。

在多线程的环境下，如果某个线程首次读取共享变量，则首先到主内存中获取该变量，然后存入工作内存中，以后只需要在工作内存中读取该变量即可。同样如果对该变量执行了修改的操作，则先将新值写入工作内存中，然后再刷新至主内存中。但是刷新时间虽然很短但并不确定。

### 竞争问题
![Alt '竞争问题'](https://s2.ax1x.com/2019/12/30/lQPnSK.png)
如果这两个加1操作是串行的，最终主内存中的count的是3。然而图中两个加1操作是并行的，当它们值更新到工作内存的副本后，会争相刷新主内存。在这里，不管是线程1还是线程2先刷新计算结果到主内存，最终主内存中的值只能是2。



## 重排序

除了共享内存和工作内存带来的问题，还存在重排序的问题：在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。

### 分类
一个好的内存模型实际上会放松对处理器和编译器规则的束缚，也就是说软件技术和硬件技术都为同一个目标而进行奋斗：在不改变程序执行结果的前提下，尽可能提高并行度。JMM对底层尽量减少约束，使其能够发挥自身优势。因此，在执行程序时，
**为了提高性能，编译器和处理器常常会对指令进行重排序**。一般重排序可以分为如下三种：
![Alt "指令重排序"](https://s2.ax1x.com/2019/12/30/lMlgJS.png)

>1. 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序；
>2. 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果**不存在数据依赖性**，处理器可以改变语句对应机器指令的执行顺序；
>3. 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行的。

注: 指令并行重排序和内存系统重排序统称为处理器排序

### 依赖性
我们知道重排序是编译器或者系统的优化。但是如果有些指令存在依赖性的话，进行重排序会导致错误。

* 数据依赖性  
如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分为下列3种类型，这3种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变。

|名称 | 说明 | 示例|
| :-: | :-: | :-: |
|写后读 | 写一个变量，再读这个变量  | a = 1; b = a; |
|写后写| 写一个变量，再写这个变量 | a = 1; a = 2; |
|读后写| 读一个变量, 再写这个变量 | a = b; b = 1; |

这三种操作都存在数据依赖性，如果重排序最终会导致结果受到影响。  

* 控制依赖性
```java
public void method() {
    
    if (flag) {
        int num = a * a;
        return num;
    }
}
```
在上面的代码中，我们可以知道变量 num 的值依赖于 if( flag) 的判断值, 这里就叫控制依赖。

控制依赖在单线程的情况下，对存在控制依赖的操作重排序，不会改变执行结果。但是在多线程的情况下，就有可能出现问题。

```java
public class Demo {
    int a = 0;
    boolean flag = false;
    
    public void init() {
        // 1
        a = 1;
        // 2
        flag = true;
    }
    
    public void use() {
        // 3
        if (flag) {
            // 4
            int i = a * a;
        }
    }
}
```

在程序中，当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（Reorder Buffer，ROB）的硬件缓存中。当操作3的条件判断为真时，就把该计算结果写入变量i中。猜测执行实质上对操作3和4做了重排序，问题在于这时候，a的值还没被线程A赋值。

当操作1和操作2重排序，操作3和操作4重排序时，可能会产生什么效果？操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还没有被线程A写入，这时就会发生错误！

所以在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。


### as-if-serial
不管如何重排序，都必须保证代码在单线程下的运行正确，连单线程下都无法正确，更不用讨论多线程并发的情况，所以就提出了一个 as-if-serial 的概念。

**as-if-serial:** 不管怎么重排序 (编译器和处理器为了提高并行度)，(单线程)程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守 as-if-serial 语义。  
为了遵守 as-if-serial 语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作依然可能被编译器和处理器重排序。

**as-if-serial** 语义把单线程程序保护了起来，遵守 as-if-serial 语义的编译器、runtime 和处理器可以让我们感觉到：单线程程序看起来是按程序的顺序来执行的。asif-serial 语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。

### 内存屏障
Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序，从而让程序按我们预想的流程去执行
>1. 保证特定操作的执行顺序
>2. 影响某些数据（或则是某条指令的执行结果）的内存可见性

编译器和 CPU 能够重排序指令，保证最终相同的结果前提，尝试优化性能。插入一条 Memory Barrier 会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序。

Memory Barrier 所做的另外一件事是强制刷出各种 CPU cache，如一个 Write-Barrier（写入屏障）将刷出所有在 Barrier 之前写入 cache 的数据，因此，任何 CPU 上的线程都能读取到这些数据的最新版本。

JMM把内存屏障指令分为4类：
| 屏障类型| 说明 | 实例 |
| :-: | :-: | :-: |
| LoadLoadBarriers| Load1; LoadLoadBarriers; Load2 | 确保 Load1 数据的读取 在 load2 及 后续指令的读取之前|
| StoreStoreBarriers | Store1; StoreStoreBarriers; Store2; | 确保 Store1 数据的写入(刷新到主内存) 在 Store2 及后续指令的读取之前 |
|LoadStoreBarriers| Load1; LoadStoreBarriers; Store2; | 确保 Load1 数据的读取 在Store2 及后续指令的写入之前 |
| StoreLoadBarriers | Store1; StoreLoadBarriers; Load2; | 确保 Store2 数据的写入 在 Load2 及后续指令的读取之前 |

StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。

## happens-before

在 Java 规范提案中为让大家理解内存可见性的这个概念，提出了 happens-before 的概念来阐述操作之间的内存可见性。  
JMM 这么做的原因是：程序员对于这两个操作是否真的被重排序并不关心，程序员关心的是程序执行时的语义不能被改变（即执行结果不能被改变）。因此，happens-before 关系本质上和 as-if-serial 语义是一回事。as-if-serial 语义保证单线程内程序的执行结果不被改变，happens-before 关系保证正确同步的多线程程序的执行结果不被改变。

### 定义
>1. 如果一个操作 happens-before 另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。
>2. 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。

上面的定义看起来很矛盾，其实它是站在不同的角度来说的。  
1: 站在Java程序员的角度来说：JMM保证，如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。  
2: 站在编译器和处理器的角度来说：JMM允许，两个操作之间存在happens-before关系，不要求Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序是允许的

### as-if-serial VS happens-before
>1. as-if-serial 语义保证单线程内程序的执行结果不被改变，happens-before 关系保证正确同步的多线程程序的执行结果不被改变。
>2. as-if-serial 语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before 关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按 happens-before 指定的顺序来执行的。
>3. as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。

### 具体的规则
>1. 程序顺序规则：一个线程中的每个操作，happens-before 于该线程中的任意后续操作。
>2. 监视器锁规则：对一个锁的解锁，happens-before 于随后对这个锁的加锁。
>3. volatile变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个volatile域的读。
>4. 传递性：如果 A happens-before B，且 B happens-before C，那么 A happens-before C。
>5. start()规则：如果线程 A 执行操作 ThreadB.start()（启动线程B），那么 A 线程的 ThreadB.start() 操作happens-before 于线程 B 中的任意操作。
>6. join()规则：如果线程 A 执行操作 ThreadB.join() 并成功返回，那么线程 B 中的任意操作 happens-before 于线程 A 从 ThreadB.join() 操作成功返回。
>7. 程序中断规则：对线程 interrupted() 方法的调用 happens-before 于被中断线程的代码检测到中断时间的发生。
>8. 对象finalize规则：一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始。


https://blog.csdn.net/weixin_44367006/article/details/99656558
https://www.codercc.com/post/812b4c63.html











DCL
https://www.cnblogs.com/timlearn/p/4125297.html



这些重排序在多线程的情况下可能会导致线程安全的问题，一个很经典的例子就是 DCL 问题。针对编译器重排序，JMM的编译器重排序规则会禁止一些特定类型的编译器重排序；针对处理器重排序(指令并行重排序和内存系统重排序统称为处理器排序)，编译器在生成指令序列的时候会通过插入内存屏障指令来禁止某些特殊的处理器重排序。（内存屏障的知识就不展开了）

### 依赖性






参考  
《Java 多线程编程实践实战指南（核心篇）》  
[再有人问你Java内存模型是什么，就把这篇文章发给他。](https://www.hollischuang.com/archives/2550)  
[Java 内存模型详解](https://juejin.im/post/5d3eafe95188255d3d296e09)  
[java内存模型以及happens-bofore原则](https://www.codercc.com/post/812b4c63.html)  
[JMM和底层实现原理](https://www.jianshu.com/p/8a58d8335270)  
[大厂很可能会问到的JMM底层实现原理](https://blog.csdn.net/weixin_44367006/article/details/99656558)